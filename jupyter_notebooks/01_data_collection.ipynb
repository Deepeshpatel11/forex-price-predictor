{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0aStgWSO0E0E"
      },
      "source": [
        "# 01 Data Collection – Forex Price Prediction Project"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1eLEkw5O0ECa"
      },
      "source": [
        "## Objectives\n",
        "\n",
        "* Fetch historical OHLCV (Open, High, Low, Close, Volume) data for 10 selected forex pairs using the OANDA API.\n",
        "* Save the raw data in CSV format in the `data/raw/` directory for further processing.\n",
        "\n",
        "## Inputs\n",
        "\n",
        "* OANDA API Key stored securely in `.env` file.\n",
        "* Selected forex pairs:\n",
        "  1. GBP/USD  \n",
        "  2. EUR/GBP  \n",
        "  3. EUR/USD  \n",
        "  4. AUD/USD  \n",
        "  5. NZD/USD  \n",
        "  6. USD/JPY  \n",
        "  7. USD/SGD  \n",
        "  8. USD/CHF  \n",
        "  9. USD/CAD  \n",
        "  10. GBP/CAD\n",
        "* Desired number of historical candles per pair and timeframe (e.g., last 1000 H4 candles).\n",
        "\n",
        "## Outputs\n",
        "\n",
        "* 10 CSV files stored in `data/raw/` named as:\n",
        "  * GBP_USD_forex_data.csv\n",
        "  * EUR_GBP_forex_data.csv\n",
        "  * EUR_USD__forex_data.csv\n",
        "  * AUD_USD_forex_data.csv\n",
        "  * NZD_USD_forex_data.csv\n",
        "  * USD_JPY_forex_data.csv\n",
        "  * USD_SGD_forex_data.csv\n",
        "  * USD_CHF_forex_data.csv\n",
        "  * USD_CAD_forex_data.csv\n",
        "  * GBP_CAD_forex_data.csv \n",
        "\n",
        "* Each CSV contains:\n",
        "  - `timestamp`  \n",
        "  - `open`  \n",
        "  - `high`  \n",
        "  - `low`  \n",
        "  - `close`  \n",
        "  - `volume`  \n",
        "\n",
        "## Additional Comments\n",
        "\n",
        "* This notebook covers the **Data Collection** step of CRISP-DM.\n",
        "* The raw files will be used in **02_data_cleaning_feature_engineering.ipynb** for feature creation.\n",
        "* Ensure that the `.env` file with `OANDA_API_KEY` is correctly configured before running this notebook.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9uWZXH9LwoQg"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cqP-UeN-z3i2"
      },
      "source": [
        "# Change working directory"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aOGIGS-uz3i2"
      },
      "source": [
        "We need to change the working directory from its current folder to its parent folder\n",
        "* We access the current directory with os.getcwd()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "wZfF_j-Bz3i4",
        "outputId": "66943449-1436-4c3d-85c7-b85f9f78349b"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'/workspaces/forex-price-predictor/jupyter_notebooks'"
            ]
          },
          "execution_count": 1,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import os\n",
        "current_dir = os.getcwd()\n",
        "current_dir"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9MWW8E7lz3i7"
      },
      "source": [
        "We want to make the parent of the current directory the new current directory\n",
        "* os.path.dirname() gets the parent directory\n",
        "* os.chir() defines the new current directory"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "TwHsQRWjz3i9",
        "outputId": "86849db3-cd2f-4cc5-ebb8-2d0caafa1a2c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "You set a new current directory\n"
          ]
        }
      ],
      "source": [
        "os.chdir(os.path.dirname(current_dir))\n",
        "print(\"You set a new current directory\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M_xPk_Ijz3i-"
      },
      "source": [
        "Confirm the new current directory"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "vz3S-_kjz3jA",
        "outputId": "00b79ae4-75d0-4a96-d193-ac9ef9847ea2"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'/workspaces/forex-price-predictor'"
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "current_dir = os.getcwd()\n",
        "current_dir"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-mavJ8DibrcQ"
      },
      "source": [
        "# Import Libraries & Load API Key"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Purpose: Import dependencies and load OANDA API key securely."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "OANDA_API_KEY loaded: True\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "from dotenv import load_dotenv\n",
        "\n",
        "# Load environment variables from .env file\n",
        "load_dotenv()\n",
        "\n",
        "# Retrieve OANDA API key\n",
        "OANDA_API_KEY = os.getenv(\"OANDA_API_KEY\")\n",
        "\n",
        "# Verify that the key is loaded\n",
        "print(\"OANDA_API_KEY loaded:\", bool(OANDA_API_KEY))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZY3l0-AxO93d"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uFQo3ycuO-v6"
      },
      "source": [
        "## Define Forex Pairs & Data Collection Plan"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "In this step, we will define the **10 forex pairs** for which we will collect **1-hour (H1) OHLCV data**.\n",
        "\n",
        "- Each pair will have approximately **8,760 candles (~1 year)**.\n",
        "- The raw CSV files will be saved in the folder: `data/raw/`.\n",
        "- The raw data will include:\n",
        "  - `timestamp`\n",
        "  - `open`\n",
        "  - `high`\n",
        "  - `low`\n",
        "  - `close`\n",
        "  - `volume`\n",
        "\n",
        "**Selected Pairs:**\n",
        "1. GBP/USD  \n",
        "2. EUR/GBP  \n",
        "3. EUR/USD  \n",
        "4. AUD/USD  \n",
        "5. NZD/USD  \n",
        "6. USD/JPY  \n",
        "7. USD/SGD  \n",
        "8. USD/CHF  \n",
        "9. USD/CAD  \n",
        "10. GBP/CAD"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting 8760 candles per pair (H1)\n",
            "Pairs: ['GBP_USD', 'EUR_GBP', 'EUR_USD', 'AUD_USD', 'NZD_USD', 'USD_JPY', 'USD_SGD', 'USD_CHF', 'USD_CAD', 'GBP_CAD']\n"
          ]
        }
      ],
      "source": [
        "PAIRS = [\n",
        "    \"GBP_USD\", \"EUR_GBP\", \"EUR_USD\", \"AUD_USD\", \"NZD_USD\",\n",
        "    \"USD_JPY\", \"USD_SGD\", \"USD_CHF\", \"USD_CAD\", \"GBP_CAD\"\n",
        "]\n",
        "\n",
        "# Number of candles ~1 year of 1-hour data\n",
        "NUM_CANDLES = 8760\n",
        "TIMEFRAME = \"H1\"\n",
        "\n",
        "# Ensure raw data directory exists\n",
        "import os\n",
        "os.makedirs(\"data/raw\", exist_ok=True)\n",
        "\n",
        "print(f\"Collecting {NUM_CANDLES} candles per pair ({TIMEFRAME})\")\n",
        "print(\"Pairs:\", PAIRS)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Test Data Fetch for One Pair\n",
        "\n",
        "Before fetching data for all 10 pairs,  \n",
        "we will **test the `fetch_live_data()` function** for a single pair (EUR/USD):\n",
        "\n",
        "- Fetch **1 year (~8,760) of 1-hour candles**  \n",
        "- Preview the first few rows to confirm:\n",
        "  - Columns: `timestamp, open, high, low, close, volume`  \n",
        "  - Correct number of rows fetched\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>timestamp</th>\n",
              "      <th>open</th>\n",
              "      <th>high</th>\n",
              "      <th>low</th>\n",
              "      <th>close</th>\n",
              "      <th>volume</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2024-03-06 03:00:00+00:00</td>\n",
              "      <td>1.08527</td>\n",
              "      <td>1.08533</td>\n",
              "      <td>1.08504</td>\n",
              "      <td>1.08508</td>\n",
              "      <td>1905</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2024-03-06 04:00:00+00:00</td>\n",
              "      <td>1.08508</td>\n",
              "      <td>1.08524</td>\n",
              "      <td>1.08495</td>\n",
              "      <td>1.08519</td>\n",
              "      <td>1408</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2024-03-06 05:00:00+00:00</td>\n",
              "      <td>1.08518</td>\n",
              "      <td>1.08570</td>\n",
              "      <td>1.08516</td>\n",
              "      <td>1.08552</td>\n",
              "      <td>1866</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2024-03-06 06:00:00+00:00</td>\n",
              "      <td>1.08549</td>\n",
              "      <td>1.08607</td>\n",
              "      <td>1.08549</td>\n",
              "      <td>1.08595</td>\n",
              "      <td>2183</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2024-03-06 07:00:00+00:00</td>\n",
              "      <td>1.08594</td>\n",
              "      <td>1.08666</td>\n",
              "      <td>1.08586</td>\n",
              "      <td>1.08621</td>\n",
              "      <td>4008</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                  timestamp     open     high      low    close  volume\n",
              "0 2024-03-06 03:00:00+00:00  1.08527  1.08533  1.08504  1.08508    1905\n",
              "1 2024-03-06 04:00:00+00:00  1.08508  1.08524  1.08495  1.08519    1408\n",
              "2 2024-03-06 05:00:00+00:00  1.08518  1.08570  1.08516  1.08552    1866\n",
              "3 2024-03-06 06:00:00+00:00  1.08549  1.08607  1.08549  1.08595    2183\n",
              "4 2024-03-06 07:00:00+00:00  1.08594  1.08666  1.08586  1.08621    4008"
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from src.data_collection import fetch_live_data\n",
        "\n",
        "# Fetch sample data\n",
        "sample_df = fetch_live_data(\"EUR_USD\", candles=NUM_CANDLES, timeframe=TIMEFRAME)\n",
        "\n",
        "# Display first 5 rows\n",
        "sample_df.head()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Fetch and Save Data for All 10 Forex Pairs\n",
        "\n",
        "Now that we have successfully tested fetching data for a single pair (EUR/USD),  \n",
        "we will proceed to collect **1 year (~8,760 1-hour candles)** for all 10 selected forex pairs.\n",
        "\n",
        "- Each dataset will be saved in the folder: `data/raw/`\n",
        "- Files will follow the naming convention:\n",
        "Example: `GBP_USD_forex_data.csv`\n",
        "- Columns included:\n",
        "  - `timestamp`\n",
        "  - `open`\n",
        "  - `high`\n",
        "  - `low`\n",
        "  - `close`\n",
        "  - `volume`\n",
        "\n",
        "This will complete the **Data Collection step** of our CRISP-DM workflow.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Fetching data for GBP_USD ...\n",
            "❌ Error fetching data for GBP_USD: ('Connection aborted.', RemoteDisconnected('Remote end closed connection without response'))\n",
            "❌ No data fetched for GBP_USD\n",
            "\n",
            "Fetching data for EUR_GBP ...\n",
            "✅ Saved 8759 rows to data/raw/EUR_GBP_forex_data.csv\n",
            "\n",
            "Fetching data for EUR_USD ...\n",
            "✅ Saved 8759 rows to data/raw/EUR_USD_forex_data.csv\n",
            "\n",
            "Fetching data for AUD_USD ...\n",
            "✅ Saved 8759 rows to data/raw/AUD_USD_forex_data.csv\n",
            "\n",
            "Fetching data for NZD_USD ...\n",
            "✅ Saved 8759 rows to data/raw/NZD_USD_forex_data.csv\n",
            "\n",
            "Fetching data for USD_JPY ...\n",
            "✅ Saved 8759 rows to data/raw/USD_JPY_forex_data.csv\n",
            "\n",
            "Fetching data for USD_SGD ...\n",
            "✅ Saved 8759 rows to data/raw/USD_SGD_forex_data.csv\n",
            "\n",
            "Fetching data for USD_CHF ...\n",
            "✅ Saved 8759 rows to data/raw/USD_CHF_forex_data.csv\n",
            "\n",
            "Fetching data for USD_CAD ...\n",
            "✅ Saved 8759 rows to data/raw/USD_CAD_forex_data.csv\n",
            "\n",
            "Fetching data for GBP_CAD ...\n",
            "✅ Saved 8759 rows to data/raw/GBP_CAD_forex_data.csv\n",
            "\n",
            "\n",
            "--- Bulk Fetch Completed ---\n",
            "⚠ The following pairs failed and need retrying: ['GBP_USD']\n"
          ]
        }
      ],
      "source": [
        "import time\n",
        "\n",
        "failed_pairs = []\n",
        "\n",
        "for pair in PAIRS:\n",
        "    print(f\"Fetching data for {pair} ...\")\n",
        "    \n",
        "    try:\n",
        "        df = fetch_live_data(pair, candles=NUM_CANDLES, timeframe=TIMEFRAME)\n",
        "        \n",
        "        if not df.empty:\n",
        "            save_path = f\"data/raw/{pair}_forex_data.csv\"\n",
        "            df.to_csv(save_path, index=False)\n",
        "            print(f\"Saved {len(df)} rows to {save_path}\\n\")\n",
        "        else:\n",
        "            print(f\"No data fetched for {pair}\\n\")\n",
        "            failed_pairs.append(pair)\n",
        "            \n",
        "    except Exception as e:\n",
        "        print(f\"Error fetching {pair}: {e}\\n\")\n",
        "        failed_pairs.append(pair)\n",
        "    \n",
        "    # Pause to avoid hitting API rate limits\n",
        "    time.sleep(3)\n",
        "\n",
        "print(\"\\n--- Bulk Fetch Completed ---\")\n",
        "if failed_pairs:\n",
        "    print(\"⚠ The following pairs failed and need retrying:\", failed_pairs)\n",
        "else:\n",
        "    print(\"All pairs fetched successfully!\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Note:**  \n",
        "GBP/USD data was initially difficult to fetch due to an OANDA API timeout.  \n",
        "It was successfully collected after isolating the pair and fetching in smaller batches.  \n",
        "All 10 forex pairs now have 1-year (H1) OHLCV data stored in `data/raw/`.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✅ Saved 8759 rows to data/raw/GBP_USD_forex_data.csv\n"
          ]
        }
      ],
      "source": [
        "# Retry only GBP/USD separately\n",
        "pair = \"GBP_USD\"\n",
        "df = fetch_live_data(pair, candles=NUM_CANDLES, timeframe=TIMEFRAME)\n",
        "\n",
        "if not df.empty:\n",
        "    save_path = f\"data/raw/{pair}_forex_data.csv\"\n",
        "    df.to_csv(save_path, index=False)\n",
        "    print(f\"Saved {len(df)} rows to {save_path}\")\n",
        "else:\n",
        "    print(f\"Still no data for {pair}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Raw files saved:\n",
            " - data/raw/GBP_USD_forex_data.csv\n",
            " - data/raw/USD_JPY_forex_data.csv\n",
            " - data/raw/USD_SGD_forex_data.csv\n",
            " - data/raw/USD_CHF_forex_data.csv\n",
            " - data/raw/USD_CAD_forex_data.csv\n",
            " - data/raw/NZD_USD_forex_data.csv\n",
            " - data/raw/EUR_USD_forex_data.csv\n",
            " - data/raw/EUR_GBP_forex_data.csv\n",
            " - data/raw/GBP_CAD_forex_data.csv\n",
            " - data/raw/AUD_USD_forex_data.csv\n",
            "\n",
            "Total files saved: 10\n",
            "\n",
            "Preview of first file:\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>timestamp</th>\n",
              "      <th>open</th>\n",
              "      <th>high</th>\n",
              "      <th>low</th>\n",
              "      <th>close</th>\n",
              "      <th>volume</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2024-03-06 04:00:00+00:00</td>\n",
              "      <td>1.26993</td>\n",
              "      <td>1.27028</td>\n",
              "      <td>1.26978</td>\n",
              "      <td>1.27020</td>\n",
              "      <td>2121</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2024-03-06 05:00:00+00:00</td>\n",
              "      <td>1.27022</td>\n",
              "      <td>1.27068</td>\n",
              "      <td>1.27018</td>\n",
              "      <td>1.27038</td>\n",
              "      <td>1940</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2024-03-06 06:00:00+00:00</td>\n",
              "      <td>1.27037</td>\n",
              "      <td>1.27074</td>\n",
              "      <td>1.27028</td>\n",
              "      <td>1.27048</td>\n",
              "      <td>2582</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2024-03-06 07:00:00+00:00</td>\n",
              "      <td>1.27049</td>\n",
              "      <td>1.27156</td>\n",
              "      <td>1.27032</td>\n",
              "      <td>1.27107</td>\n",
              "      <td>5915</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2024-03-06 08:00:00+00:00</td>\n",
              "      <td>1.27106</td>\n",
              "      <td>1.27256</td>\n",
              "      <td>1.27090</td>\n",
              "      <td>1.27256</td>\n",
              "      <td>5703</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                   timestamp     open     high      low    close  volume\n",
              "0  2024-03-06 04:00:00+00:00  1.26993  1.27028  1.26978  1.27020    2121\n",
              "1  2024-03-06 05:00:00+00:00  1.27022  1.27068  1.27018  1.27038    1940\n",
              "2  2024-03-06 06:00:00+00:00  1.27037  1.27074  1.27028  1.27048    2582\n",
              "3  2024-03-06 07:00:00+00:00  1.27049  1.27156  1.27032  1.27107    5915\n",
              "4  2024-03-06 08:00:00+00:00  1.27106  1.27256  1.27090  1.27256    5703"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "import glob\n",
        "\n",
        "# List all raw CSV files\n",
        "raw_files = glob.glob(\"data/raw/*_forex_data.csv\")\n",
        "\n",
        "print(\"Raw files saved:\")\n",
        "for file in raw_files:\n",
        "    print(\" -\", file)\n",
        "\n",
        "print(f\"\\nTotal files saved: {len(raw_files)}\")\n",
        "\n",
        "# Optional: Preview first few rows of one file\n",
        "if raw_files:\n",
        "    sample_preview = pd.read_csv(raw_files[0]).head()\n",
        "    print(\"\\nPreview of first file:\")\n",
        "    display(sample_preview)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ltNetd085qHf"
      },
      "source": [
        "# Push files to Repo"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 1. Check current git status\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "On branch main\n",
            "Your branch is up to date with 'origin/main'.\n",
            "\n",
            "Changes not staged for commit:\n",
            "  (use \"git add <file>...\" to update what will be committed)\n",
            "  (use \"git restore <file>...\" to discard changes in working directory)\n",
            "\t\u001b[31mmodified:   .gitignore\u001b[m\n",
            "\t\u001b[31mmodified:   jupyter_notebooks/01_data_collection.ipynb\u001b[m\n",
            "\t\u001b[31mmodified:   src/data_collection.py\u001b[m\n",
            "\n",
            "Untracked files:\n",
            "  (use \"git add <file>...\" to include in what will be committed)\n",
            "\t\u001b[31mdata/\u001b[m\n",
            "\n",
            "no changes added to commit (use \"git add\" and/or \"git commit -a\")\n"
          ]
        }
      ],
      "source": [
        "!git status"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 2. Stage all new/updated files"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "fatal: pathspec 'notebooks/01_data_collection.ipynb' did not match any files\n"
          ]
        }
      ],
      "source": [
        "!git add data/raw/*.csv notebooks/01_data_collection.ipynb"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 3. Commit with a descriptive message"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "On branch main\n",
            "Your branch is up to date with 'origin/main'.\n",
            "\n",
            "Changes not staged for commit:\n",
            "  (use \"git add <file>...\" to update what will be committed)\n",
            "  (use \"git restore <file>...\" to discard changes in working directory)\n",
            "\t\u001b[31mmodified:   .gitignore\u001b[m\n",
            "\t\u001b[31mmodified:   jupyter_notebooks/01_data_collection.ipynb\u001b[m\n",
            "\t\u001b[31mmodified:   src/data_collection.py\u001b[m\n",
            "\n",
            "Untracked files:\n",
            "  (use \"git add <file>...\" to include in what will be committed)\n",
            "\t\u001b[31mdata/\u001b[m\n",
            "\n",
            "no changes added to commit (use \"git add\" and/or \"git commit -a\")\n"
          ]
        }
      ],
      "source": [
        "!git commit -m \"Add raw forex OHLCV data for 10 pairs (Notebook 01)\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 4. Push to the main branch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Everything up-to-date\n"
          ]
        }
      ],
      "source": [
        "!git push origin main"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "* In case you don't need to push files to Repo, you may replace this section with \"Conclusions and Next Steps\" and state your conclusions and next steps."
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "Data Practitioner Jupyter Notebook.ipynb",
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "3.12.1",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.1"
    },
    "orig_nbformat": 2
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
